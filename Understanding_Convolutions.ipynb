{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding Convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtpzBc9Iv4fcDGmZBpSExJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SArham/understanding_ml/blob/master/Understanding_Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGIQHWTyoh8u",
        "colab_type": "text"
      },
      "source": [
        "# **Understanding Convolutions**\n",
        "\n",
        "\n",
        "Hi, to understand convolutions, we are going to need to learn a couple of basics beforehand.\n",
        "\n",
        "We need to know about\n",
        "\n",
        "1.   Linear Algebra\n",
        "2.   Matrices\n",
        "3.   Programming\n",
        "\n",
        "\n",
        "Linear Algebra and Matrices:\n",
        "\n",
        "Here, I will just refer you to [3blue1brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab). This playlist will teach you everything and more you need to know about to understand convolutions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-B0507ggLdZ",
        "colab_type": "text"
      },
      "source": [
        "# **What is a Convolution?**\n",
        "\n",
        "[Maths](https://en.wikipedia.org/wiki/Convolution): A mathematical operation on two functions (f and g) that produces a third function expressing how the shape of one is modified by the other.\n",
        "\n",
        "In the context of a Neural Network, a convolution is the process of a [kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)) [a matrix of (n, m) shape] sliding across the input matrix and each point the filter moves to, the output is written a corresponding location in the output matrix.\n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/ad00478081591e8d289b7b1eba7448050acb1fed)\n",
        "\n",
        "Mathematically, the Convolution we perform in ANNs, is [Cross-corelation.](https://en.wikipedia.org/wiki/Cross-correlation)\n",
        "\n",
        "Visually, this is how the above equation processes like.\n",
        "\n",
        "\n",
        "![alt text](https://media.giphy.com/media/i4NjAwytgIRDW/source.gif)\n",
        "\n",
        "The filter is usually a square in shape. \n",
        "\n",
        "The input to the convolution will always be larger or equal to its output.\n",
        "\n",
        "Each step of this process, the hadamard product is calculated of the cropped input and the kernel/filter. The output of the operation is then summed/weighted summed and the result is set as the pixel value of the output matrix.\n",
        "\n",
        "The [Hadamard Product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)) is just the fancy-shmancy word for element-wise product of 2 matrices. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx5cUnMebWcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from math import floor, ceil\n",
        "from random import randint\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDWe2R1lcebx",
        "colab_type": "text"
      },
      "source": [
        "The following function allows you to download images from their url. \n",
        "You can do the following:\n",
        "1.   You can supply the url to the function from where to fetch the image.\n",
        "2.   You can set the location where the image would be saved.\n",
        "\n",
        "If you do not provide it a url or a saving location. It will \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ3bbPAbbpBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Photo by chuttersnap on Unsplash. It's a pretty big image.\n",
        "def get_image(url='https://unsplash.com/photos/dCSdghHE6IE/download?force=true', \n",
        "              location=\"./test.jpg\",\n",
        "\t\t\t\t\t\t\toverwrite=False):\n",
        "\tif overwrite or not os.path.exists(location):\n",
        "\t\tf = open(location, 'wb')\n",
        "\t\tf.write(requests.get(url).content)\n",
        "\t\tf.close()\n",
        "\timage = cv2.imread(location)\n",
        "\tbg_im = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\treturn bg_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JhlPnlWRBz5",
        "colab_type": "text"
      },
      "source": [
        "# **calculate_output_size:**\n",
        "\n",
        "Receives:\n",
        "1.  l = The input dimension to the convolution.\n",
        "2.  k = kernel size.\n",
        "3.  p = padding size\n",
        "4.  s = stride lenght.\n",
        "\n",
        "\n",
        "To check if the output of the convolution is correct. Enter the kernel size, stride and padding values in the following calculator by fomoro.\n",
        "\n",
        "VALID padding means that \n",
        "https://fomoro.com/research/article/receptive-field-calculator\n",
        "\n",
        "# **convolution2D:**\n",
        "\n",
        "Receives \n",
        "1.  an image [a matrix of size w x h], 2 dimensional input matrix\n",
        "2.  an optional input of a 2D kernel/filter matrix can be given. It has to be a numpy array. \n",
        "3.  [optional] stride of the kernel ca nbe given.\n",
        "4.  [optional] kernel size can be given. This will be overwritten if a kernel is inputted into the function.\n",
        "5.  padding can be set to VALID=False, or SAME=True.\n",
        "\n",
        "Logic:\n",
        "\n",
        "\n",
        "If the kernel/filter is not given. A random filter is created from a uniform distribution between the values of -100 to 100 of the of the matrix size [kernel_size, kernel_size].\n",
        "Otherwise, the entered filter's size is retrieved and set to the kernel_size.\n",
        "\n",
        "The weight \"normalizes\" the element-wise product. \n",
        "\n",
        "The input matrix dimensions are set to h, w.\n",
        "\n",
        "[Padding is calculated](https://stats.stackexchange.com/questions/297678/how-to-calculate-optimal-zero-padding-for-convolutional-neural-networks) :\n",
        "Padding = (Kernel_Sizeâˆ’1) / 2\n",
        "\n",
        "\n",
        "If we want to pad, we pad accordingly, otherwise, we don't. \n",
        "\n",
        "Then we calculate the output shape after the convolution operation.\n",
        "\n",
        "We create the output matrix and fill it with zeros.\n",
        "\n",
        "Iterating is different for padded and non-padded inputs. Although, both ranges start from the same value, the padded input starts from the (0, 0) value of the original image while the non-padded input starts from the ( [kernel_size/2] /  [kernel_size/2] ) value. This is why, the output dimesion decreases by this (kernel_size/2) value. This happens, as without padding, at matrix center (0, 0), of the input, a cropped matrix of (kernel_size)/(kernel_size) is impossible as you will be going out of bound at the left and top side.e\n",
        "\n",
        "We iterate through the input matrix according to the stride. Crop out an area equal to the filter and then calculate the elementwise product of the filter and the cropped input. We sum it and place at the appropriate index of the output matrix.\n",
        "\n",
        "1.  j represents the height index.\n",
        "2.  i represents the width index.\n",
        "\n",
        "Once, we have iterated through all the points/pixels/indexes/locations of the input matrix with the filter, we have an output matrix and we return it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyufWHWN1yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_output_size(l, k, p, s):\n",
        "\treturn int(((l-k +(2*p))/s)+ 1)\n",
        "\n",
        "def convolution2D(image, filter=None, stride=5, kernel_size=4, padding=False):\t\n",
        "  # https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
        "  if filter is None:\n",
        "    filter = np.random.uniform(low=-100.0, high=100.0, size=(kernel_size, kernel_size))\n",
        "  else:\n",
        "    kernel_size = filter.shape[0]\n",
        "  weight = 1./np.sum(filter, axis=(0, 1))\n",
        "  # [https://wikimedia.org/api/rest_v1/media/math/render/svg/ad00478081591e8d289b7b1eba7448050acb1fed]\n",
        "\n",
        "  h, w = image.shape\n",
        "\n",
        "  padded = ceil((kernel_size-1)/2)\n",
        "  if padding:\n",
        "    image = np.pad(image, padded, 'constant', constant_values=0)\n",
        "    oh, ow = calculate_output_size(h, kernel_size, padded, stride), \\\n",
        "              calculate_output_size(w, kernel_size, padded, stride)\n",
        "  else:\n",
        "    oh, ow = calculate_output_size(h, kernel_size, 0, stride), \\\n",
        "              calculate_output_size(w, kernel_size, 0, stride)\n",
        "  post_processed_image = np.zeros((oh, ow))\n",
        "  oi, oj = 0, 0\n",
        "  jrange = range(padded, h+padded, stride) if padding else range(padded, h-padded, stride)\n",
        "  irange = range(padded, w+padded, stride) if padding else range(padded, w-padded, stride)\n",
        "  for j in jrange:\n",
        "    oi = 0\n",
        "    for i in irange:\n",
        "      cropped_area = image[(j-padded):(j+kernel_size-padded), \n",
        "                (i-padded):(i+kernel_size-padded)]\n",
        "      v = weight * np.sum(cropped_area * filter, axis=(0, 1))\n",
        "      v = 0 if v < 0 else 255 if v > 255 else v\n",
        "      post_processed_image[oj, oi] = v\n",
        "      oi += 1\n",
        "    oj += 1\n",
        "  print(f'{image.shape} ---> {post_processed_image.shape},'\n",
        "        +f'{filter.shape}, {stride}, {padding}')\n",
        "  return post_processed_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyEIbair2Diu",
        "colab_type": "text"
      },
      "source": [
        "# Let's play this out like how a normal network would... in the start.\n",
        "\n",
        "The function below takes the image, we downloaded and does the convolution n amounts of times. You can set it however many times you want to but be vary with the speed at which the image size decreases. This is one of the main reasons convolutions are used for images. \n",
        "\n",
        "They, inherently, take into consideration the location of pixels and their distance to one another. They also decrease the dimensionality of the output considerably allowing for leaner and less complex computation and networks.\n",
        "\n",
        "If you are using the image, I am using, the first layer will take some time but the rest would be much much faster due to the size and thus the no. of calculations required.\n",
        "\n",
        "Play around, all inputs are tuples or lists with the first value being the inclusive lower bound and the 2nd value being the exclusive upper bound value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knMpCI0hb0Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_random(no_of_convs, strides, ksizes):\n",
        "\timage_list = []\n",
        "\timage_list.append(get_image())\n",
        "\tfor i in range(randint(no_of_convs[0], no_of_convs[1])):\n",
        "\t\timage_list.append(convolution2D(image_list[-1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstride=randint(strides[0], strides[1]), \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tkernel_size=randint(ksizes[0], ksizes[1]), \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpadding=(True if randint(0, 1)== 1 else False)))\n",
        "\tfor imid, image in enumerate(image_list):\n",
        "\t\tcv2.imwrite(f\"./processed{imid}.jpg\", image)\n",
        "\treturn image_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX4j5re7b2d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_list = process_random((2, 7), (1, 4), (3, 7))\n",
        "\n",
        "for imid, image in enumerate(im_list):\n",
        "  im = cv2.resize(cv2.imread(f'./processed{imid}.jpg'), (720, 480), cv2.INTER_LINEAR)\n",
        "  cv2_imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN00XRVypU-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread(\"./test.jpg\")\n",
        "im1 = convolution2D(image, stride=4, kernel_size=5, padding=True)\n",
        "cv2_imshow(im1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FO4-IMP03h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filters = [[[0, 0, 0], [0, 1, 0], [0, 0, 0]],             # Identity\n",
        "           [[1, 0, -1], [0, 0, 0], [-1, 0, 1]],           # Edge Detection [Roberts]\n",
        "           [[0, -1, 0], [-1, 4, -1], [0, -1, 0]],            # Edge Detection [Laplacian] \n",
        "           [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]],     # Edge Detection [Laplacian]\n",
        "           [[0, -1, 0], [-1, 5, -1], [0, -1, 0]],         # Sharpening\n",
        "           [[1, 0, -1], [2, 0, -2], [1, 0, -1]],          # Vertical Sobel-Feldman a.k.a Sobel \n",
        "           [[1, 2, 1], [0, 0, 0], [-1, -2, -1]],          # Horizontal Sobel\n",
        "           [[3, 0, -3], [10, 0, -10], [3, 0, -3]],        # factored Vertical Sobel \n",
        "           [[3, 10, 3], [0, 0, 0], [-3, -10, -3]],        # factored Horizontal Sobel\n",
        "           [[47, 0, -47], [162, 0 , -162], [47, 0, -47]], # Vertical Scharr\n",
        "           [[47, 162, 47], [0, 0, 0], [-47, -162, -47]]   # Horizontal Scharr\n",
        "           ]\n",
        "filters = np.asarray(filters)\n",
        "image = cv2.resize(get_image(), (720, 480), cv2.INTER_LINEAR)\n",
        "for filter in filters:\n",
        "  fimage = convolution2D(image, filter, stride=2, padding=True)\n",
        "  cv2_imshow(fimage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7XyuIcmTAHw",
        "colab_type": "text"
      },
      "source": [
        "Now, the function for convolution above does more than most basic convolution, it takes into account padding and the stride of the kernel too. \n",
        "We have not delved into what these 2 parameters are and what they do. \n",
        "\n",
        "**What does stride mean?**\n",
        "\n",
        "Just like how a person walks and each step is said to be a stride. The movement of the kernel along the input matrix is said to be it's stride.\n",
        "\n",
        "Stride is the movement distance of the kernel about the input matrix in the x/y/z/.. axis. The impact of stride on the output is such that it reduces the size of the output by 1/stride. As you can see in the calculate_output_size() function. \n",
        "  \n",
        "![alt text](https://wikimedia.org/api/rest_v1/media/math/render/svg/a5325dc0b1b8695f19ec8fe3485d0da19040c622)\n",
        "\n",
        "W = Input size\n",
        "\n",
        "K = Kernel Size\n",
        "\n",
        "P = Padding Needed. = (K-1)/2\n",
        "\n",
        "S = Stride\n",
        "\n",
        "\n",
        "\n",
        "**What  is padding?**\n",
        "\n",
        "Padding, as the name suggests, is the step where the input matrix is padded at each end of each axis so that with stride=1, the input matrix is the same shape as the output matrix.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2560/1*LykM0S7xsbLVd0eGbW_rig.gif)\n",
        "\n",
        "Normally, in computer vision, we do zero padding. There are other types of edge handling [procedures](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Edge_Handling)\n",
        "\n",
        "\n",
        "Let's look at pytorch's [convolution2d layer.](https://pytorch.org/docs/stable/nn.html#conv2d)\n",
        "\n",
        "\n",
        "It is just one line of code. All of the above logic, plus more, on the GPU and CPU, with better optimization for you to use. Ain't that amazing. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVul2KhbQfxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "b4700700-515e-4dfd-c23c-342dfe6fb546"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from random import randint\n",
        "\n",
        "\n",
        "get_image()\n",
        "image = torch.Tensor(np.moveaxis(np.asarray(cv2.imread(\"test.jpg\")), -1, 0)).unsqueeze(0)\n",
        "image.shape\n",
        "\n",
        "def get_conv(kernel_size=3, stride=2, padding=True):\n",
        "  print(f'filter of ({kernel_size}, {kernel_size}) with stride={stride} and padding={padding}')\n",
        "  if padding:\n",
        "    return nn.Conv2d(3, 1, kernel_size, stride=stride, \n",
        "                     padding=ceil((kernel_size-1)/2))\n",
        "  return nn.Conv2d(3, 1, kernel_size, stride=stride)\n",
        "\n",
        "conv2d = get_conv(randint(2, 7), randint(1, 5), True)\n",
        "out = conv2d(image).detach().numpy().squeeze()\n",
        "print(f\"Image of size {real_image.shape} converted into {out.shape}\")\n",
        "out = cv2.resize(out, (720, 480), cv2.INTER_LINEAR)\n",
        "cv2_imshow(out)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "filter of (5, 5) with stride=1 and padding=True\n",
            "Image of size (4016, 6016) converted into (4016, 6016)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAAAAACprgVwAAAHi0lEQVR4nO3dW3fbxhEA4MGNIClS\nEi1LTnua05PTt/7/n5S3NDfLFkWKAPrARo5spyEjkADB73uSbFEYC6Pl7OxiHQEAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwAtJ1wFAi9JR\n1xF0oOw6AA4mXXcdQQcm864j4FDSpusIOlB/86brEDiQtOsAulDnf3/bdQwcxlkmdFM1f7vtOggO\nIu86gC5Uj1mtuzNMZ5nQm2XyuOw6CA7iPBP6oanqroPgIM6yho6onqquQ+AgznKETtaRnGO78hyc\nZUI3RRVGaIYjyTU5AAAAoP/2Wyo504UVgE7osAIAAABnKes6AAAAAAAAAAD4gi3+AAAAAAAAAAAA\nAAAAMHgeIwKAA/NmCwAAAAC9o20HAABAr+RXXUcALbrpOgAGoD/9u1HXAQAAfNKfIgkAAGAQTLP6\nqphPug7hFEnoPhvA3RnAP4HXmsSq7joGaE8SkXcdQ0vSrgPgr2n1rbUZTkJDRERkXQfQEiP0sbQ8\nW2k7AU2mGBQlB70zlLIBgGe5yRRnxZSRQZLYnISy6wDg6FLjM0MinzkVRdcBwLFZS2RAkvy5Uz1O\nk1CAcOpO4/w0C0TD18I9vowsknw0fv13OjQJPXyt3OMqss3mcftxEhdf/H1fOtkSevg2r/8WTxHx\n8LyZbzpefJ7RZT57/VXaYOrKDsbZh4ikHtVJ01Tx8erh8y9IHpou4vrSuY7QfpH3sqojosqStNhk\nkWZPD5+N+slju/mshbIvCb2ftIzkt9WXZPL55PCuP48WnOuNbaGuPCv1Kpqn7YfjSV5vXvz88rTq\nIqavOteSYxiOfveKiEiXq+TlhZuPx44DWpNEWX7+JwfQnyrm9G1/lqexMnYw24r5d2mVTrZ5nHxx\nqGPRozmckuMrtvdn3XEUOzrUmaHb3c+/K47rqrkqLyKaZYxfJk4hizr3f/dLpn/+Jefgi3E3+epn\nueKAE5SNXnbE/vf7nt1kk0haH6LLv1ryebNgN/n65drJb028qhrPmtZP4x1fZU9tf89z16OZTi9M\nR1lSzD6V7NvtHN+lEZcRd21frZxMn6+xDyP0H+rJ5oTe2MSoePqwfC48ts3nqo5oZvHY8sXS2bKJ\nuNDg5kAmkU0jIklfPvu9iFiU8/koIuatXu8i4vrdvNx7wmmEZifLKJuIrKnrpvhd/+fnNFZ5UU7j\nRYfv9UZVRLFJT+CJgk4oh1uwTa7RkZ4nXMT1Ip4fkbk8/AU5T6OI9Ajr0nnEqMwuZpHNIyLefrvr\n/NDY9YdyO/K6dL1MmiK5T96lP67Sm6QcL7/vOiT469JJxDQiZu8WkX1zGXEXuzzlZVJIL03rZcQ6\niVit61g81NmsebdLOSGhT9pV1wEczMPtdRqbIqJJ5pOH/Ppt+VTtsh6phj5toxPZE7i32/v14sc3\nP0VExLTIq3m2il+WHQfFoBy1KXwXo7j61/Ont+92fJ0ReiCG1pP5x8Ov4002Wu07KKuhB+JYN/JY\nI2Ad1SgefrmJi/6cysQRDe2tdl7GPOJm/iYuJj05lIkWDC1PdzaLmES5iFhc3cXbrqNhoIrj1qhJ\nxHT+3Zuk3Y18nLK2h/jjvWUkERFpJHdxe+MBT9r06WnC4z4QW0TEZcRt7F50nOtRYOxjE3mz3e98\n3DO/niKijPghJp4sp13HHvmyLMoiprfbh79vdl7U0YdmF9vSuTheYtdFuop4KC/XERHL6ZEuS7+1\nN5dKsjh2BT3O07jZ7utXGZ+6Qx3w9Sqj5Ijv6NksyWNyF0nEZR5RxGSntD7bxj37SOvIo0nq1g+U\n+WNlU8Z9/Pv7WF38NKrK8ufdXiah+yrrzyHiMaqqiCiOepZRNvkQ2Xh6n1STGP2QbyK9WKf2j562\nnjzs3F0F+/ZicnM5/WfxNrmOSHdpRuty9FQao4j3XUex1d3O1MdZ/Bj5Ov7TfJxf1qsdXiGhe6o+\nlfOpD2gWm4d1vnz/eB0xreqLXUoeCX36DrvPocM1ug8R91ebp1iv8qvlZFTtkqwS+vQddq7W6dz0\ncbaJN1Hmm9ts89N8s8OR0TrW9FMxWm3yfD3N7udVE+/X9fyHXV5mhKaf8mYeo8dqXTzVo2V8HK/e\ndB0RvMLlZUREtogob7Ldd/gboemn0fuIiOsPEbOqWkXMd5ufWimkv7KmHiebcdzHzuuURmh6K6/q\ncV0+ZavId+7lSGh6axPxlDWTX/Zpxmnb0WdV9usikj3+TyIjNL2V30RaztazB7sAGIjL9Jtv9zqV\nQ8lBn72PZGN8ZjiSxafOcj51mgHDUZRmfAyDTAYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACg\n15I//xIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjuq/EJUX+z/wBJEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=720x480 at 0x7FC084479F98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANkS8sofzclx",
        "colab_type": "text"
      },
      "source": [
        "And that was quite a lot of information to unload but I hope I was able to provide it in a simple but detailed manner. There are alot of references in this and they are definetely recommeded reads for you if you want to understand convolutions in more detail.\n",
        "\n",
        "\n",
        "Check us out at https://visiongenius.ai.\n",
        "\n",
        "Arham."
      ]
    }
  ]
}